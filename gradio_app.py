#!/usr/bin/env python3
"""
Gradio app for Weathering Model.

3-step workflow:
  Step 1: VLM ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
  Step 2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
  Step 3: ãƒ•ãƒ¬ãƒ¼ãƒ é€£ç¶šç”Ÿæˆ

Usage:
    cd /work/DDIPM/kfukushima/wsim
    python3 gradio_app.py [--port 7860] [--device cuda]
"""

import argparse
import os
import sys
import tempfile
import threading
from pathlib import Path

import gradio as gr
from PIL import Image

# weathering_model / vlm ã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§ import ã™ã‚‹ãŒã€
# é‡ã„ãƒ¢ãƒ‡ãƒ«ã¯å‘¼ã³å‡ºã—æ™‚ã«åˆã‚ã¦ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
sys.path.insert(0, str(Path(__file__).parent))
import vlm as vlm_module
from weathering_model import WeatheringModel


# ---------------------------------------------------------------------------
# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰: ã‚·ãƒ³ã‚°ãƒ«ãƒ¦ãƒ¼ã‚¶æƒ³å®šï¼‰
# ---------------------------------------------------------------------------
_weathering_model: WeatheringModel | None = None
_model_lock = threading.Lock()


def _get_weathering_model(device: str) -> WeatheringModel:
    global _weathering_model
    if _weathering_model is None:
        with _model_lock:
            if _weathering_model is None:
                print("Loading WeatheringModel...")
                _weathering_model = WeatheringModel(device=device)
                print("WeatheringModel loaded.")
    return _weathering_model


# ---------------------------------------------------------------------------
# Step 1: VLM ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
# ---------------------------------------------------------------------------
def step1_generate_prompt(image, device):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‹ã‚‰VLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    if image is None:
        return gr.update(), gr.update(value="âš ï¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    # PIL ç”»åƒã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆvlm ã¯ file path ã‚’å—ã‘å–ã‚‹ï¼‰
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        tmp_path = tmp.name
        if isinstance(image, str):
            img = Image.open(image).convert("RGB")
        else:
            img = Image.fromarray(image).convert("RGB")
        img.save(tmp_path)

    try:
        input_prompt, output_prompt, instruction = vlm_module.vlm_inference(
            mode="age", image_path=tmp_path
        )
        return (
            gr.update(value=input_prompt),
            gr.update(value=output_prompt),
            gr.update(value="âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†"),
        )
    except Exception as e:
        return (
            gr.update(),
            gr.update(),
            gr.update(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"),
        )
    finally:
        os.unlink(tmp_path)


# ---------------------------------------------------------------------------
# Step 2: å­¦ç¿’
# ---------------------------------------------------------------------------
def step2_train(image, input_prompt, output_prompt, learning_rate, train_steps, lora_rank, device):
    """WeatheringModel ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹"""
    if image is None:
        yield gr.update(value="âš ï¸ Step 1 ã§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        return
    if not input_prompt.strip():
        yield gr.update(value="âš ï¸ Input Prompt ãŒç©ºã§ã™")
        return

    yield gr.update(value="ğŸ”„ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = _get_weathering_model(device)

    # ç”»åƒã®æº–å‚™
    if isinstance(image, str):
        pil_img = Image.open(image).convert("RGB")
    else:
        pil_img = Image.fromarray(image).convert("RGB")

    # output_prompt ã‚’ train_prompt ã¨ã—ã¦ä½¿ã†ï¼ˆå­¦ç¿’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ = åŠ£åŒ–å¾Œã®çŠ¶æ…‹ï¼‰
    train_prompt = output_prompt.strip() if output_prompt.strip() else input_prompt.strip()

    yield gr.update(value=f"ğŸ”„ å­¦ç¿’é–‹å§‹... (LR={learning_rate}, Steps={train_steps}, Rank={lora_rank})")

    try:
        # LoRA rank ã‚’è¨­å®š
        model.RANK = int(lora_rank)

        # ãƒ­ã‚°åé›†ï¼ˆtqdm ã¯ stderr ã«å‡ºã‚‹ã®ã§ stdout ã«åˆ‡ã‚Šæ›¿ãˆï¼‰
        old_stdout = sys.stdout
        log_lines = []

        class LogCapture:
            def write(self, s):
                old_stdout.write(s)
                if s.strip():
                    log_lines.append(s.strip())
            def flush(self):
                old_stdout.flush()

        sys.stdout = LogCapture()
        try:
            model.train_only(
                input_image=pil_img,
                train_prompt=train_prompt,
                learning_rate=float(learning_rate),
                train_steps=int(train_steps),
            )
        finally:
            sys.stdout = old_stdout

        yield gr.update(value="âœ… å­¦ç¿’å®Œäº†ï¼Step 3 ã§ç”Ÿæˆã§ãã¾ã™\n" + "\n".join(log_lines[-10:]))

    except Exception as e:
        import traceback
        yield gr.update(value=f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼:\n{traceback.format_exc()}")


# ---------------------------------------------------------------------------
# Step 3: ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
# ---------------------------------------------------------------------------
def step3_generate(output_prompt, negative_prompt, num_frames, guidance_scale, attn_word, device):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã™ã‚‹"""
    model = _get_weathering_model(device)

    if not hasattr(model, "input_image") or model.input_image is None:
        return [], "âš ï¸ å…ˆã« Step 2 ã®å­¦ç¿’ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„"

    if not output_prompt.strip():
        return [], "âš ï¸ Output Prompt ãŒç©ºã§ã™"

    try:
        frames = model.generate_frames(
            inference_prompt=output_prompt.strip(),
            negative_prompt=negative_prompt.strip(),
            attn_word=attn_word.strip() if attn_word.strip() else None,
            guidance_scale=float(guidance_scale),
            num_frames=int(num_frames),
        )
        return frames, f"âœ… {len(frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆå®Œäº†"
    except Exception as e:
        import traceback
        return [], f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{traceback.format_exc()}"


# ---------------------------------------------------------------------------
# Gradio UI
# ---------------------------------------------------------------------------
def build_ui(device: str):
    css = """
    .tab-header { font-size: 1.1rem; font-weight: 700; }
    .status-box { font-size: 0.85rem; }
    """

    with gr.Blocks(title="Weathering Model", css=css, theme=gr.themes.Soft()) as demo:
        gr.Markdown("# âš™ï¸ Weathering Model")
        gr.Markdown("3ã‚¹ãƒ†ãƒƒãƒ—ã§ç”»åƒã®çµŒå¹´å¤‰åŒ–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

        # å…±æœ‰ã‚¹ãƒ†ãƒ¼ãƒˆ
        shared_image = gr.State(None)
        shared_input_prompt = gr.State("")
        shared_output_prompt = gr.State("")

        with gr.Tabs():

            # ====== Tab 1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ======
            with gr.Tab("Step 1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"):
                gr.Markdown("### å…¥åŠ›ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦VLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t1_image = gr.Image(label="å…¥åŠ›ç”»åƒ", type="numpy")
                        t1_btn = gr.Button("ğŸ¤– VLM ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ", variant="primary")
                    with gr.Column(scale=1):
                        t1_input_prompt = gr.Textbox(
                            label="Input Promptï¼ˆç·¨é›†å¯ï¼‰",
                            placeholder="ä¾‹: A clean car",
                            lines=2,
                        )
                        t1_status = gr.Textbox(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=1, elem_classes="status-box")

                t1_btn.click(
                    fn=step1_generate_prompt,
                    inputs=[t1_image, gr.State(device)],
                    outputs=[t1_input_prompt, shared_output_prompt, t1_status],
                )

            # ====== Tab 2: å­¦ç¿’ ======
            with gr.Tab("Step 2: å­¦ç¿’"):
                gr.Markdown("### å…¥åŠ›ç”»åƒã¨ç”Ÿæˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦LoRAã§å­¦ç¿’ã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t2_image = gr.Image(label="å…¥åŠ›ç”»åƒï¼ˆStep 1 ã¨åŒã˜ï¼‰", type="numpy")
                        t2_input_prompt = gr.Textbox(
                            label="Input Promptï¼ˆå­¦ç¿’ç”¨ï¼‰",
                            placeholder="Step 1 ã‹ã‚‰è‡ªå‹•ã§ã‚³ãƒ”ãƒ¼ã€ã¾ãŸã¯ç›´æ¥å…¥åŠ›",
                            lines=2,
                        )
                        t2_output_prompt = gr.Textbox(
                            label="Output Promptï¼ˆå­¦ç¿’ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼‰",
                            placeholder="Step 1 ã‹ã‚‰è‡ªå‹•ã§ã‚³ãƒ”ãƒ¼ã€ã¾ãŸã¯ç›´æ¥å…¥åŠ›",
                            lines=2,
                        )
                    with gr.Column(scale=1):
                        t2_lr = gr.Number(label="Learning Rate", value=1e-5, precision=8)
                        t2_steps = gr.Slider(label="Train Steps", minimum=50, maximum=1000, step=50, value=450)
                        t2_rank = gr.Slider(label="LoRA Rank", minimum=2, maximum=64, step=2, value=8)
                        t2_btn = gr.Button("ğŸš€ å­¦ç¿’é–‹å§‹", variant="primary")
                        t2_log = gr.Textbox(label="å­¦ç¿’ãƒ­ã‚°", interactive=False, lines=8, elem_classes="status-box")

                t2_btn.click(
                    fn=step2_train,
                    inputs=[t2_image, t2_input_prompt, t2_output_prompt, t2_lr, t2_steps, t2_rank, gr.State(device)],
                    outputs=[t2_log],
                )

                # Step 1 â†’ Step 2 ã¸ã®å€¤å¼•ãç¶™ããƒœã‚¿ãƒ³
                with gr.Row():
                    sync_btn = gr.Button("â†© Step 1 ã®ç”»åƒãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼•ãç¶™ã")

                def _sync_from_step1(img, inp, out):
                    return img, inp, out

                sync_btn.click(
                    fn=_sync_from_step1,
                    inputs=[t1_image, t1_input_prompt, shared_output_prompt],
                    outputs=[t2_image, t2_input_prompt, t2_output_prompt],
                )

            # ====== Tab 3: ç”Ÿæˆ ======
            with gr.Tab("Step 3: ç”Ÿæˆ"):
                gr.Markdown("### å­¦ç¿’æ¸ˆã¿LoRAã§é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t3_output_prompt = gr.Textbox(
                            label="Output Promptï¼ˆç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰",
                            placeholder="ä¾‹: A heavily rusted car",
                            lines=2,
                        )
                        t3_negative_prompt = gr.Textbox(
                            label="Negative Prompt",
                            placeholder="ï¼ˆä»»æ„ï¼‰",
                            lines=2,
                            value="",
                        )
                        t3_attn_word = gr.Textbox(
                            label="Aging Attention Wordï¼ˆä»»æ„ï¼‰",
                            placeholder="ä¾‹: rusted",
                            lines=1,
                            value="",
                        )
                        t3_num_frames = gr.Slider(label="Num Frames", minimum=1, maximum=20, step=1, value=5)
                        t3_guidance = gr.Slider(label="Guidance Scale", minimum=1.0, maximum=20.0, step=0.5, value=7.5)
                        t3_btn = gr.Button("ğŸï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ", variant="primary")
                        t3_status = gr.Textbox(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=1, elem_classes="status-box")
                    with gr.Column(scale=2):
                        t3_gallery = gr.Gallery(label="ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ", columns=5, height="auto")

                # Step 2 â†’ Step 3 ã¸ã®å€¤å¼•ãç¶™ããƒœã‚¿ãƒ³
                with gr.Row():
                    sync_btn3 = gr.Button("â†© Step 2 ã® Output Prompt ã‚’å¼•ãç¶™ã")

                sync_btn3.click(
                    fn=lambda x: x,
                    inputs=[t2_output_prompt],
                    outputs=[t3_output_prompt],
                )

                t3_btn.click(
                    fn=step3_generate,
                    inputs=[t3_output_prompt, t3_negative_prompt, t3_num_frames, t3_guidance, t3_attn_word, gr.State(device)],
                    outputs=[t3_gallery, t3_status],
                )

    return demo


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=int, default=7860)
    parser.add_argument("--host", type=str, default="0.0.0.0")
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--share", action="store_true")
    args = parser.parse_args()

    demo = build_ui(device=args.device)
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
    )


if __name__ == "__main__":
    main()

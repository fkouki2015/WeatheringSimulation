#!/usr/bin/env python3
"""
Gradio app for Weathering Model.

3-step workflow:
  Step 1: VLM ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
  Step 2: ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
  Step 3: ãƒ•ãƒ¬ãƒ¼ãƒ é€£ç¶šç”Ÿæˆ

Usage:
    cd /work/DDIPM/kfukushima/wsim
    python3 gradio_app.py [--port 7860] [--device cuda]
"""

import argparse
import os
import queue
import sys
import tempfile
import threading
import traceback
from pathlib import Path

import gradio as gr
from PIL import Image

# weathering_model / vlm ã¯ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ã§ import ã™ã‚‹ãŒã€
# é‡ã„ãƒ¢ãƒ‡ãƒ«ã¯å‘¼ã³å‡ºã—æ™‚ã«åˆã‚ã¦ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹ï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰
sys.path.insert(0, str(Path(__file__).parent))
import vlm as vlm_module
from weathering_model import WeatheringModel


# ---------------------------------------------------------------------------
# ã‚°ãƒ­ãƒ¼ãƒãƒ«çŠ¶æ…‹ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³å…±æœ‰: ã‚·ãƒ³ã‚°ãƒ«ãƒ¦ãƒ¼ã‚¶æƒ³å®šï¼‰
# ---------------------------------------------------------------------------
_weathering_model: WeatheringModel | None = None
_model_lock = threading.Lock()


def _get_weathering_model(device: str) -> WeatheringModel:
    global _weathering_model
    if _weathering_model is None:
        with _model_lock:
            if _weathering_model is None:
                print("Loading WeatheringModel...")
                _weathering_model = WeatheringModel(device=device)
                print("WeatheringModel loaded.")
    return _weathering_model


# ---------------------------------------------------------------------------
# Step 1: VLM ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
# ---------------------------------------------------------------------------
def step1_generate_prompt(image, device):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‹ã‚‰VLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    if image is None:
        # 7ã¤ã®å‡ºåŠ›ã«å¯¾å¿œã—ãŸç©ºã®updateã‚’è¿”ã™
        return gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(), gr.update(value="âš ï¸ ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    # PIL ç”»åƒã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆvlm ã¯ file path ã‚’å—ã‘å–ã‚‹ï¼‰
    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        tmp_path = tmp.name
        if isinstance(image, str):
            img = Image.open(image).convert("RGB")
        else:
            img = Image.fromarray(image).convert("RGB")
        img.save(tmp_path)

    try:
        input_prompt, output_prompt, instruction = vlm_module.vlm_inference(
            mode="age", image_path=tmp_path
        )
        # vlm_module.unload_vlm()
        return (
            gr.update(value=input_prompt),   # t1_input_prompt
            gr.update(value=output_prompt),  # shared_output_prompt
            gr.update(value=image),          # t2_imageï¼ˆStep2ã«è‡ªå‹•åæ˜ ï¼‰
            gr.update(value=input_prompt),   # t2_input_promptï¼ˆStep2ã«è‡ªå‹•åæ˜ ï¼‰
            gr.update(value=output_prompt),  # t1_output_promptï¼ˆStep1ã«è¡¨ç¤ºï¼‰
            gr.update(value=output_prompt),  # t3_output_promptï¼ˆStep3ã«è‡ªå‹•åæ˜ ï¼‰
            gr.update(value="âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆå®Œäº†"),
        )
    except Exception as e:
        # vlm_module.unload_vlm()
        return (
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(),
            gr.update(value=f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"),
        )
    finally:
        os.unlink(tmp_path)


# ---------------------------------------------------------------------------
# Step 2: å­¦ç¿’
# ---------------------------------------------------------------------------
def step2_train(image, input_prompt, output_prompt, learning_rate, train_steps, lora_rank, use_early_stopping, device,
                progress=gr.Progress()):
    """WeatheringModel ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿè¡Œã™ã‚‹"""
    if image is None:
        yield gr.update(value="âš ï¸ Step 1 ã§ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        return
    if not input_prompt.strip():
        yield gr.update(value="âš ï¸ Input Prompt ãŒç©ºã§ã™")
        return

    progress(0, desc="ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...")
    yield gr.update(value="ğŸ”„ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­...")
    model = _get_weathering_model(device)

    if isinstance(image, str):
        pil_img = Image.open(image).convert("RGB")
    else:
        pil_img = Image.fromarray(image).convert("RGB")

    train_prompt = input_prompt.strip()
    total_steps = int(train_steps)

    progress(0, desc=f"å­¦ç¿’æº–å‚™ä¸­... (Steps={total_steps}, æ—©æœŸåœæ­¢={'ON' if use_early_stopping else 'OFF'})")
    yield gr.update(value=f"ğŸ”„ å­¦ç¿’é–‹å§‹... (LR={learning_rate}, Steps={total_steps}, Rank={lora_rank}, æ—©æœŸåœæ­¢={'ON' if use_early_stopping else 'OFF'})")

    log_queue = queue.Queue()
    train_done = threading.Event()
    train_error = [None]

    def progress_callback(step, loss_val, total):
        # ("prog", ...) ã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°ç”¨
        log_queue.put(("prog", step, total, loss_val))

    class LogCapture:
        def write(self, s):
            sys.__stdout__.write(s)
            if s.strip():
                # ("log", ...) ã¯ãƒ†ã‚­ã‚¹ãƒˆãƒ­ã‚°è¡¨ç¤ºç”¨
                log_queue.put(("log", s.rstrip()))
        def flush(self):
            sys.__stdout__.flush()

    def train_thread():
        old_stdout = sys.stdout
        sys.stdout = LogCapture()
        try:
            model.RANK = int(lora_rank)
            model.train_only(
                input_image=pil_img,
                train_prompt=train_prompt,
                inference_prompt=output_prompt.strip(),  # è¿½åŠ : è©•ä¾¡ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                learning_rate=float(learning_rate),
                train_steps=total_steps,
                use_early_stopping=bool(use_early_stopping),
                progress_callback=progress_callback,
            )
        except Exception:
            train_error[0] = traceback.format_exc()
        finally:
            sys.stdout = old_stdout
            train_done.set()

    t = threading.Thread(target=train_thread, daemon=True)
    t.start()

    log_lines = []
    while not train_done.is_set() or not log_queue.empty():
        try:
            msg = log_queue.get(timeout=0.3)
            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚¿ã‚¤ãƒ—ã§åˆ†å²
            if isinstance(msg, tuple) and msg[0] == "prog":
                _, step, total, loss_val = msg
                progress(step / total, desc=f"å­¦ç¿’ä¸­ [{step}/{total}] Loss: {loss_val:.5f}")
            elif isinstance(msg, tuple) and msg[0] == "log":
                log_lines.append(msg[1])
                yield gr.update(value="\n".join(log_lines[-20:]))  # æœ€æ–°20è¡Œã‚’è¡¨ç¤º
            else:
                # å¿µã®ãŸã‚æ—§å½¢å¼(æ–‡å­—åˆ—)ã‚‚å¯¾å¿œ
                log_lines.append(str(msg))
                yield gr.update(value="\n".join(log_lines[-20:]))
        except queue.Empty:
            pass
    t.join()

    if train_error[0]:
        yield gr.update(value=f"âŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼:\n{train_error[0]}")
    else:
        yield gr.update(value="âœ… å­¦ç¿’å®Œäº†ï¼Step 3 ã§ç”Ÿæˆã§ãã¾ã™\n" + "\n".join(log_lines[-30:]))


# ---------------------------------------------------------------------------
# Step 3: ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ
# ---------------------------------------------------------------------------
def step3_generate(output_prompt, negative_prompt, num_frames, guidance_scale, attn_word, device):
    """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã™ã‚‹"""
    model = _get_weathering_model(device)

    if not hasattr(model, "input_image") or model.input_image is None:
        return [], "âš ï¸ å…ˆã« Step 2 ã®å­¦ç¿’ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„"

    if not output_prompt.strip():
        return [], "âš ï¸ Output Prompt ãŒç©ºã§ã™"

    try:
        frames = model.generate_frames(
            inference_prompt=output_prompt.strip(),
            negative_prompt=negative_prompt.strip(),
            attn_word=attn_word.strip() if attn_word.strip() else None,
            guidance_scale=float(guidance_scale),
            num_frames=int(num_frames),
        )
        return frames, f"âœ… {len(frames)} ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆå®Œäº†"
    except Exception as e:
        import traceback
        return [], f"âŒ ç”Ÿæˆã‚¨ãƒ©ãƒ¼:\n{traceback.format_exc()}"


# ---------------------------------------------------------------------------
# Gradio UI
# ---------------------------------------------------------------------------
def build_ui(device: str):
    css = """
    .tab-header { font-size: 1.1rem; font-weight: 700; }
    .status-box {
        font-size: 0.85rem;
    }
    """

    with gr.Blocks(title="Weathering Simulation", css=css, theme=gr.themes.Soft()) as demo:
        gr.Markdown("# Weathering Simulation")
        gr.Markdown("3ã‚¹ãƒ†ãƒƒãƒ—ã§ç”»åƒã®çµŒå¹´å¤‰åŒ–ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

        # å…±æœ‰ã‚¹ãƒ†ãƒ¼ãƒˆ
        shared_image = gr.State(None)
        shared_input_prompt = gr.State("")
        shared_output_prompt = gr.State("")

        with gr.Tabs():

            # ====== Tab 1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ ======
            with gr.Tab("Step 1: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ"):
                gr.Markdown("### å…¥åŠ›ç”»åƒã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦VLMã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t1_image = gr.Image(label="å…¥åŠ›ç”»åƒ", type="numpy")
                        t1_btn = gr.Button("ğŸ¤– VLM ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ", variant="primary")
                    with gr.Column(scale=1):
                        t1_input_prompt = gr.Textbox(
                            label="Input Promptï¼ˆç·¨é›†å¯ï¼‰",
                            placeholder="ä¾‹: A clean car",
                            lines=2,
                        )
                        t1_output_prompt = gr.Textbox(
                            label="Output Promptï¼ˆç·¨é›†å¯ï¼‰",
                            placeholder="ä¾‹: A heavily rusted car",
                            lines=2,
                        )
                        t1_status = gr.Textbox(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=2, elem_classes="status-box")

            # ====== Tab 2: å­¦ç¿’ ======
            with gr.Tab("Step 2: å­¦ç¿’"):
                gr.Markdown("### å…¥åŠ›ç”»åƒã¨ç”Ÿæˆæ¸ˆã¿ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ã£ã¦LoRAã§å­¦ç¿’ã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t2_image = gr.Image(label="å…¥åŠ›ç”»åƒï¼ˆStep 1 ã¨åŒã˜ï¼‰", type="numpy")
                        t2_input_prompt = gr.Textbox(
                            label="Input Promptï¼ˆå­¦ç¿’ç”¨ï¼‰",
                            placeholder="Step 1 ã‹ã‚‰è‡ªå‹•ã§ã‚³ãƒ”ãƒ¼ã€ã¾ãŸã¯ç›´æ¥å…¥åŠ›",
                            lines=2,
                        )
                    with gr.Column(scale=1):
                        t2_lr = gr.Number(label="Learning Rate", value=1e-5, precision=8)
                        t2_steps = gr.Slider(label="Max Train Steps", minimum=50, maximum=1000, step=50, value=450)
                        t2_rank = gr.Slider(label="LoRA Rank", minimum=2, maximum=64, step=2, value=8)
                        t2_early_stop = gr.Checkbox(label="æ—©æœŸåœæ­¢ã‚’ä½¿ç”¨ï¼ˆLPIPSè©•ä¾¡ï¼‰", value=True)
                        t2_btn = gr.Button("ğŸš€ å­¦ç¿’é–‹å§‹", variant="primary")
                        t2_log = gr.Textbox(label="å­¦ç¿’ãƒ­ã‚°", interactive=False, lines=8, elem_classes="status-box")

                t2_btn.click(
                    fn=step2_train,
                    inputs=[t2_image, t2_input_prompt, shared_output_prompt, t2_lr, t2_steps, t2_rank, t2_early_stop, gr.State(device)],
                    outputs=[t2_log],
                )

            # ====== Tab 3: ç”Ÿæˆ ======
            with gr.Tab("Step 3: ç”Ÿæˆ"):
                gr.Markdown("### å­¦ç¿’æ¸ˆã¿LoRAã§é€£ç¶šãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ç”Ÿæˆã—ã¾ã™")
                with gr.Row():
                    with gr.Column(scale=1):
                        t3_output_prompt = gr.Textbox(
                            label="Output Promptï¼ˆç”Ÿæˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼‰",
                            placeholder="ä¾‹: A heavily rusted car",
                            lines=2,
                        )
                        t3_negative_prompt = gr.Textbox(
                            label="Negative Prompt",
                            placeholder="ï¼ˆä»»æ„ï¼‰",
                            lines=2,
                            value="",
                        )
                        t3_attn_word = gr.Textbox(
                            label="Aging Attention Wordï¼ˆä»»æ„ï¼‰",
                            placeholder="ä¾‹: rusted",
                            lines=1,
                            value="",
                        )
                        t3_num_frames = gr.Slider(label="Num Frames", minimum=1, maximum=20, step=1, value=5)
                        t3_guidance = gr.Slider(label="Guidance Scale", minimum=1.0, maximum=20.0, step=0.5, value=7.5)
                        t3_btn = gr.Button("ğŸï¸ ãƒ•ãƒ¬ãƒ¼ãƒ ç”Ÿæˆ", variant="primary")
                        t3_status = gr.Textbox(label="ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", interactive=False, lines=2, elem_classes="status-box")
                    with gr.Column(scale=2):
                        t3_gallery = gr.Gallery(label="ç”Ÿæˆãƒ•ãƒ¬ãƒ¼ãƒ ", columns=5, height="auto")

                t3_btn.click(
                    fn=step3_generate,
                    inputs=[t3_output_prompt, t3_negative_prompt, t3_num_frames, t3_guidance, t3_attn_word, gr.State(device)],
                    outputs=[t3_gallery, t3_status],
                )

        # Tab 1 ãƒœã‚¿ãƒ³ â†’ Tab 2/3 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å¼•ãç¶™ãï¼ˆTabs ãƒ–ãƒ­ãƒƒã‚¯å¤–ã«ç™»éŒ²ã—UnboundLocalErrorã‚’å›é¿ï¼‰
        t1_btn.click(
            fn=step1_generate_prompt,
            inputs=[t1_image, gr.State(device)],
            outputs=[t1_input_prompt, shared_output_prompt, t2_image, t2_input_prompt, t1_output_prompt, t3_output_prompt, t1_status],
        )

        # Step 1 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç·¨é›†æ™‚ã«å³åº§ã« Step 2/3 ã«åæ˜ 
        t1_input_prompt.change(
            fn=lambda x: x,
            inputs=[t1_input_prompt],
            outputs=[t2_input_prompt],
        )
        t1_output_prompt.change(
            fn=lambda x: (x, x),
            inputs=[t1_output_prompt],
            outputs=[shared_output_prompt, t3_output_prompt],
        )

        t1_image.change(
            fn=lambda x: x,
            inputs=[t1_image],
            outputs=[t2_image],
        )


    return demo


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--port", type=int, default=7860)
    parser.add_argument("--host", type=str, default="0.0.0.0")
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--share", action="store_true")
    args = parser.parse_args()

    demo = build_ui(device=args.device)
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=args.share,
    )


if __name__ == "__main__":
    main()
